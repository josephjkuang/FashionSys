{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Client-Side Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image as kimage\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Half of the Inference Model Stored on Client Side\n",
    "class ClientResNet(tf.keras.Model):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(ClientResNet, self).__init__(*args, **kwargs)\n",
    "        \n",
    "        # Load ResNet50 pre-trained model without top (fully connected) layers\n",
    "        resnet_base = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "        resnet_base.trainable = False\n",
    "        \n",
    "        # Get the output of the first three convolutional layers\n",
    "        middle_layer = resnet_base.get_layer('conv3_block4_out')\n",
    "        self.seq0 = Model(inputs=resnet_base.input, outputs=middle_layer.output)\n",
    "\n",
    "    # Convert image into right dimensions\n",
    "    def preprocess_image(self, img):\n",
    "        img_array = kimage.img_to_array(img)\n",
    "        expand_img = np.expand_dims(img_array, axis=0)\n",
    "        return preprocess_input(expand_img)\n",
    "\n",
    "    # Forward pass of the client model\n",
    "    def predict(self, image_path):\n",
    "        img = Image.open(image_path)\n",
    "        img = img.resize((224, 224)).convert(\"RGB\")\n",
    "\n",
    "        preprocessed_img = self.preprocess_image(img)\n",
    "        return self.seq0(preprocessed_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in Model\n",
    "ClientModel = ClientResNet()\n",
    "\n",
    "# Perform Inference on image path\n",
    "image_path = \"jeans.png\"\n",
    "client_embeddings = ClientModel.predict(image_path)\n",
    "\n",
    "# Replace: This is a mimic for sending to server\n",
    "np.save(\"client_embeddings.npy\", client_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Laplacian Noise\n",
    "client_embeddings = ClientModel.predict(image_path)\n",
    "noise_mean, noise_scale = 0.05, 0.1\n",
    "laplace_noise = np.random.laplace(noise_mean, noise_scale, size=client_embeddings.shape)\n",
    "client_embeddings += laplace_noise\n",
    "np.save(\"laplace_embeddings.npy\", client_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Siamese Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
